{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import model_and_data_serialization\n",
    "from config import *\n",
    "from single_length_train import run\n",
    "from summaries import log_run_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIMIT_BATCH: True\n",
      "PRINT_ITERATION: 1000\n",
      "CRITIC_ITERS: 5\n",
      "DISCRIMINATOR_MODEL: Discriminator_RNN\n",
      "DISC_RNN_LAYERS: 1\n",
      "MAX_N_EXAMPLES: 10000000\n",
      "NOISE_STDEV: 10.0\n",
      "SCHEDULE_SPEC: all\n",
      "GEN_ITERS: 20\n",
      "FISHER_GAN_RHO: 1e-06\n",
      "LAMBDA: 10\n",
      "PRINT_EVERY_STEP: False\n",
      "ITERATIONS_PER_SEQ_LENGTH: 15000\n",
      "SCHEDULE_ITERATIONS: False\n",
      "GEN_LR: 0.0001\n",
      "PADDING_IS_SUFFIX: False\n",
      "SAVE_CHECKPOINTS_EVERY: 3000\n",
      "GEN_RNN_LAYERS: 1\n",
      "DATA_DIR: ../Dataset/AlexaTop1M_NoSeparate\n",
      "DISC_STATE_SIZE: 512\n",
      "RNN_CELL: gru\n",
      "SCHEDULE_MULT: 2000\n",
      "GEN_STATE_SIZE: 512\n",
      "START_SEQ: 32\n",
      "CKPT_PATH: ./ckpt/\n",
      "PICKLE_PATH: ./pkl\n",
      "DYNAMIC_BATCH: False\n",
      "LOGS_DIR: ./logs/\n",
      "END_SEQ: 33\n",
      "GENERATOR_MODEL: Generator_RNN_CL_VL_TH\n",
      "DISC_LR: 0.0002\n",
      "GAN_TYPE: fgan\n",
      "BATCH_SIZE: 64\n",
      "INPUT_SAMPLE: ./output/sample.txt\n",
      "TRAIN_FROM_CKPT: False\n",
      "Loading lines, charmap, inv_charmap from pickle files.\n",
      "Load complete.\n"
     ]
    }
   ],
   "source": [
    "create_logs_dir()\n",
    "log_run_settings()\n",
    "\n",
    "_, charmap, inv_charmap = model_and_data_serialization.load_dataset(seq_length=32, b_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if FLAGS.SCHEDULE_SPEC == 'all' :\n",
    "    stages = range(FLAGS.START_SEQ, FLAGS.END_SEQ)\n",
    "else:\n",
    "    split = FLAGS.SCHEDULE_SPEC.split(',')\n",
    "    stages = map(int, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@ Stages : 32\n"
     ]
    }
   ],
   "source": [
    "print('@@@@@@@@@@@ Stages : ' + ' '.join(map(str, stages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************Training on Seq Len = 32, BATCH SIZE: 64**********************************\n",
      "Loading lines, charmap, inv_charmap from pickle files.\n",
      "Load complete.\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "(64, 512)\n",
      "WARNING:tensorflow:USING FISHER GAN OBJECTIVE FUNCTION\n",
      "Generator Params: [<tf.Variable 'Generator/Variable:0' shape=(512, 41) dtype=float32_ref>, <tf.Variable 'Generator/Variable_1:0' shape=(41,) dtype=float32_ref>, <tf.Variable 'Generator/Variable_2:0' shape=(41, 512) dtype=float32_ref>, <tf.Variable 'Generator/Variable_3:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'Generator/rnn/layer_1/gru_cell/gates/weights:0' shape=(1024, 1024) dtype=float32_ref>, <tf.Variable 'Generator/rnn/layer_1/gru_cell/gates/biases:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Generator/rnn/layer_1/gru_cell/candidate/weights:0' shape=(1024, 512) dtype=float32_ref>, <tf.Variable 'Generator/rnn/layer_1/gru_cell/candidate/biases:0' shape=(512,) dtype=float32_ref>]\n",
      "Disc Params: [<tf.Variable 'Discriminator/embedding:0' shape=(41, 512) dtype=float32_ref>, <tf.Variable 'Discriminator/rnn/gru_cell/gates/weights:0' shape=(1024, 1024) dtype=float32_ref>, <tf.Variable 'Discriminator/rnn/gru_cell/gates/biases:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Discriminator/rnn/gru_cell/candidate/weights:0' shape=(1024, 512) dtype=float32_ref>, <tf.Variable 'Discriminator/rnn/gru_cell/candidate/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'Discriminator/W:0' shape=(512, 1) dtype=float32_ref>, <tf.Variable 'Discriminator/b:0' shape=(1,) dtype=float32_ref>]\n",
      "WARNING:tensorflow:From D:\\GANDGA\\RNN.WGAN-f\\single_length_train.py:47: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:iteration 999/15000\n",
      "WARNING:tensorflow:disc cost -0.006621433887630701 gen cost -0.029431769624352455 average step time 1.1909750678539277\n",
      "WARNING:tensorflow:iteration 1999/15000\n",
      "WARNING:tensorflow:disc cost -0.03920203819870949 gen cost -0.01503785140812397 average step time 1.1895039188861847\n",
      "WARNING:tensorflow:iteration 2999/15000\n",
      "WARNING:tensorflow:disc cost -0.187973752617836 gen cost 0.1067204624414444 average step time 1.1883533127307893\n",
      "WARNING:tensorflow:iteration 3999/15000\n",
      "WARNING:tensorflow:disc cost -0.4579154849052429 gen cost 0.29129669070243835 average step time 1.1888002161979676\n",
      "WARNING:tensorflow:iteration 4999/15000\n",
      "WARNING:tensorflow:disc cost -0.6086496114730835 gen cost 0.4110410213470459 average step time 1.19025404214859\n",
      "WARNING:tensorflow:iteration 5999/15000\n",
      "WARNING:tensorflow:disc cost -0.6095675230026245 gen cost 0.40258100628852844 average step time 1.1885424201488495\n",
      "WARNING:tensorflow:iteration 6999/15000\n",
      "WARNING:tensorflow:disc cost -0.5928168892860413 gen cost 0.36247244477272034 average step time 1.1887523016929626\n",
      "WARNING:tensorflow:iteration 7999/15000\n",
      "WARNING:tensorflow:disc cost -0.5918696522712708 gen cost 0.3405601680278778 average step time 1.189165692090988\n",
      "WARNING:tensorflow:iteration 8999/15000\n",
      "WARNING:tensorflow:disc cost -0.5943734645843506 gen cost 0.3255024552345276 average step time 1.1895510272979737\n",
      "WARNING:tensorflow:iteration 9999/15000\n",
      "WARNING:tensorflow:disc cost -0.5950600504875183 gen cost 0.31812962889671326 average step time 1.1897939205169679\n",
      "WARNING:tensorflow:iteration 10999/15000\n",
      "WARNING:tensorflow:disc cost -0.589965283870697 gen cost 0.3101939558982849 average step time 1.1893579668998717\n",
      "WARNING:tensorflow:iteration 11999/15000\n",
      "WARNING:tensorflow:disc cost -0.5941665768623352 gen cost 0.3078269064426422 average step time 1.189903898715973\n",
      "WARNING:tensorflow:iteration 12999/15000\n",
      "WARNING:tensorflow:disc cost -0.6013540625572205 gen cost 0.30952465534210205 average step time 1.1888313467502594\n",
      "WARNING:tensorflow:iteration 13999/15000\n",
      "WARNING:tensorflow:disc cost -0.5998203158378601 gen cost 0.30729028582572937 average step time 1.1934808568954467\n",
      "WARNING:tensorflow:iteration 14999/15000\n",
      "WARNING:tensorflow:disc cost -0.6047531366348267 gen cost 0.3081032633781433 average step time 1.1947804417610168\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(stages)):\n",
    "    prev_seq_length = stages[i-1] if i>0 else 0\n",
    "    seq_length = stages[i]\n",
    "    print(\n",
    "    \"**********************************Training on Seq Len = %d, BATCH SIZE: %d**********************************\" % (\n",
    "    seq_length, BATCH_SIZE))\n",
    "    tf.reset_default_graph()\n",
    "    if FLAGS.SCHEDULE_ITERATIONS:\n",
    "        iterations = min((seq_length + 1) * FLAGS.SCHEDULE_MULT, FLAGS.ITERATIONS_PER_SEQ_LENGTH)\n",
    "    else:\n",
    "        iterations = FLAGS.ITERATIONS_PER_SEQ_LENGTH\n",
    "    run(iterations, seq_length, seq_length == stages[0] and not (FLAGS.TRAIN_FROM_CKPT),\n",
    "        charmap,\n",
    "        inv_charmap,\n",
    "        prev_seq_length)\n",
    "\n",
    "    if FLAGS.DYNAMIC_BATCH:\n",
    "        BATCH_SIZE = REAL_BATCH_SIZE / seq_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
